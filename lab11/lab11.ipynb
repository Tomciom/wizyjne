{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca952234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.ndimage.filters as filters\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import svm\n",
    "import random\n",
    "from skimage.transform import rotate\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80aba39",
   "metadata": {},
   "source": [
    "11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff99ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(image_rgb):\n",
    "    gradients = []\n",
    "    for i in range(image_rgb.shape[2]):\n",
    "        channel = image_rgb[:, :, i].astype(np.int32)\n",
    "        dx_channel = filters.convolve1d(channel, np.array([-1, 0, 1]), axis=1, output=np.float64, mode='constant', cval=0.0)\n",
    "        dy_channel = filters.convolve1d(channel, np.array([-1, 0, 1]), axis=0, output=np.float64, mode='constant', cval=0.0)\n",
    "        magnitude_channel = np.sqrt(dx_channel**2 + dy_channel**2)\n",
    "        orientation_channel = np.rad2deg(np.arctan2(dy_channel, dx_channel))\n",
    "        gradients.append((magnitude_channel, orientation_channel))\n",
    "\n",
    "    magnitudes_rgb = np.stack([grad[0] for grad in gradients], axis=-1)\n",
    "    orientations_rgb = np.stack([grad[1] for grad in gradients], axis=-1)\n",
    "    max_indices = np.argmax(magnitudes_rgb, axis=-1)\n",
    "    final_magnitudes = np.take_along_axis(magnitudes_rgb, np.expand_dims(max_indices, axis=-1), axis=-1).squeeze()\n",
    "    final_orientations = np.take_along_axis(orientations_rgb, np.expand_dims(max_indices, axis=-1), axis=-1).squeeze()\n",
    "    final_orientations[final_orientations < 0] += 180\n",
    "    final_orientations[final_orientations == 180] = 0\n",
    "    return final_magnitudes, final_orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9103e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell_histograms(magnitudes, orientations, cell_size=(8, 8), num_bins=9):\n",
    "    img_height, img_width = magnitudes.shape\n",
    "    cells_y = img_height // cell_size[0]\n",
    "    cells_x = img_width // cell_size[1]\n",
    "    cell_histograms = np.zeros((cells_y, cells_x, num_bins), dtype=np.float64)\n",
    "    bin_width = 180.0 / num_bins\n",
    "    for y_cell in range(cells_y):\n",
    "        for x_cell in range(cells_x):\n",
    "            cell_mag = magnitudes[y_cell*cell_size[0] : (y_cell+1)*cell_size[0],\n",
    "                                  x_cell*cell_size[1] : (x_cell+1)*cell_size[1]]\n",
    "            cell_ori = orientations[y_cell*cell_size[0] : (y_cell+1)*cell_size[0],\n",
    "                                    x_cell*cell_size[1] : (x_cell+1)*cell_size[1]]\n",
    "            for r in range(cell_mag.shape[0]):\n",
    "                for c in range(cell_mag.shape[1]):\n",
    "                    mag = cell_mag[r, c]\n",
    "                    ori = cell_ori[r, c]\n",
    "                    bin_index = int(ori // bin_width)\n",
    "                    alpha = (ori % bin_width) / bin_width\n",
    "                    current_bin = bin_index % num_bins\n",
    "                    next_bin = (bin_index + 1) % num_bins\n",
    "                    cell_histograms[y_cell, x_cell, current_bin] += mag * (1 - alpha)\n",
    "                    cell_histograms[y_cell, x_cell, next_bin] += mag * alpha\n",
    "    return cell_histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5af53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_blocks(cell_histograms, block_size=(2, 2), block_stride=(1, 1), epsilon=1e-5):\n",
    "    cells_y, cells_x, num_bins = cell_histograms.shape\n",
    "    num_blocks_y = cells_y - block_size[0] + block_stride[0]\n",
    "    num_blocks_x = cells_x - block_size[1] + block_stride[1]\n",
    "    normalized_block_vectors = []\n",
    "    for y_block in range(0, num_blocks_y, block_stride[0]):\n",
    "        for x_block in range(0, num_blocks_x, block_stride[1]):\n",
    "            block_hist_cells = cell_histograms[y_block : y_block + block_size[0],\n",
    "                                               x_block : x_block + block_size[1], :]\n",
    "            block_vector = block_hist_cells.flatten()\n",
    "            norm_sq = np.sum(block_vector**2)\n",
    "            norm = np.sqrt(norm_sq + epsilon**2)\n",
    "            if norm > 1e-6: normalized_vector = block_vector / norm\n",
    "            else: normalized_vector = block_vector \n",
    "            normalized_block_vectors.append(normalized_vector)\n",
    "    return np.array(normalized_block_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hog(image_path_or_matrix,\n",
    "                cell_size=(8, 8), num_bins=9,\n",
    "                block_size_cells=(2, 2), block_stride_cells=(1, 1),\n",
    "                norm_epsilon=1e-5):\n",
    "    if isinstance(image_path_or_matrix, str):\n",
    "        image_rgb = cv2.imread(image_path_or_matrix)\n",
    "        if image_rgb is None: raise ValueError(f\"Nie można wczytać obrazu: {image_path_or_matrix}\")\n",
    "    else:\n",
    "        image_rgb = image_path_or_matrix\n",
    "\n",
    "    if len(image_rgb.shape) == 2: image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_GRAY2BGR)\n",
    "    elif image_rgb.shape[2] == 1: image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    magnitudes, orientations = calculate_gradients(image_rgb)\n",
    "    cell_histograms_arr = create_cell_histograms(magnitudes, orientations, cell_size, num_bins)\n",
    "    normalized_blocks_list = normalize_blocks(cell_histograms_arr,\n",
    "                                              block_size_cells, block_stride_cells, norm_epsilon)\n",
    "    if len(normalized_blocks_list) > 0: hog_descriptor = np.concatenate(normalized_blocks_list)\n",
    "    else: hog_descriptor = np.array([], dtype=np.float64)\n",
    "    return hog_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOGpicture(cell_histograms, cell_size=8):\n",
    "    num_cells_y, num_cells_x, num_bins = cell_histograms.shape\n",
    "    base_line_img = np.zeros((cell_size, cell_size), dtype=np.float64)\n",
    "    center_y = cell_size // 2\n",
    "    base_line_img[center_y - 1 : center_y + 1, :] = 1.0\n",
    "    angle_step = 180.0 / num_bins\n",
    "    rotated_lines = np.zeros((cell_size, cell_size, num_bins), dtype=np.float64)\n",
    "    for k in range(num_bins):\n",
    "        angle = k * angle_step\n",
    "        rotated_img_k = rotate(base_line_img, -angle, resize=False, center=None,\n",
    "                            order=0, mode='constant', cval=0, clip=True, preserve_range=True)\n",
    "        rotated_lines[:, :, k] = rotated_img_k\n",
    "    output_image_height = num_cells_y * cell_size\n",
    "    output_image_width = num_cells_x * cell_size\n",
    "    hog_visualization = np.zeros((output_image_height, output_image_width), dtype=np.float64)\n",
    "    max_hist_val = np.max(cell_histograms)\n",
    "    scaled_cell_histograms = cell_histograms\n",
    "    if max_hist_val > 1e-6: scaled_cell_histograms = cell_histograms / max_hist_val\n",
    "    for r_cell in range(num_cells_y):\n",
    "        for c_cell in range(num_cells_x):\n",
    "            y_start, y_end = r_cell * cell_size, (r_cell + 1) * cell_size\n",
    "            x_start, x_end = c_cell * cell_size, (c_cell + 1) * cell_size\n",
    "            current_cell_visualization = np.zeros((cell_size, cell_size), dtype=np.float64)\n",
    "            for k_bin in range(num_bins):\n",
    "                weight = scaled_cell_histograms[r_cell, c_cell, k_bin]\n",
    "                current_cell_visualization += rotated_lines[:, :, k_bin] * weight\n",
    "            current_cell_visualization[current_cell_visualization > 1.0] = 1.0\n",
    "            hog_visualization[y_start:y_end, x_start:x_end] = current_cell_visualization\n",
    "    return hog_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img_path = 'pedestrians/pos/per00060.ppm'\n",
    "\n",
    "example_image_bgr = cv2.imread(example_img_path)\n",
    "example_image_rgb = cv2.cvtColor(example_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(example_image_rgb)\n",
    "plt.title(\"Oryginalny obraz (per00060.ppm)\")\n",
    "plt.show()\n",
    "\n",
    "hog_features_example = compute_hog(example_image_rgb,\n",
    "                                   cell_size=(8, 8), num_bins=9,\n",
    "                                   block_size_cells=(2, 2), block_stride_cells=(1, 1))\n",
    "\n",
    "print(f\"Długość deskryptora HOG: {len(hog_features_example)}\")\n",
    "if len(hog_features_example) == 3780:\n",
    "    print(\"Pierwsze 10 wartości HOG:\", hog_features_example[:10])\n",
    "else:\n",
    "    print(\"Nie udało się obliczyć HOG lub długość jest niepoprawna.\")\n",
    "\n",
    "print(\"\\nGenerowanie HOGPicture...\")\n",
    "mags_ex, oris_ex = calculate_gradients(example_image_rgb)\n",
    "cell_hists_ex = create_cell_histograms(mags_ex, oris_ex, cell_size=(8,8), num_bins=9)\n",
    "hog_viz_image = HOGpicture(cell_hists_ex, cell_size=8)\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.imshow(hog_viz_image, cmap='gray')\n",
    "plt.title(f\"Wizualizacja HOG dla {os.path.basename(example_img_path)}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d76367",
   "metadata": {},
   "source": [
    "11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef6ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths(folder_path, num_samples):\n",
    "    image_files = sorted([os.path.join(folder_path, f)\n",
    "                          for f in os.listdir(folder_path)\n",
    "                          if os.path.isfile(os.path.join(folder_path, f)) and (f.endswith(\".ppm\") or f.endswith(\".png\"))])\n",
    "    return image_files[:num_samples]\n",
    "\n",
    "def prepare_training_data(positive_folder, negative_folder, num_samples_each_class, hog_params, target_size=(64,128)):\n",
    "    pos_image_paths = load_image_paths(positive_folder, num_samples_each_class)\n",
    "    neg_image_paths = load_image_paths(negative_folder, num_samples_each_class)\n",
    "    hog_features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    print(f\"Przetwarzanie {len(pos_image_paths)} obrazów pozytywnych...\")\n",
    "    for img_path in tqdm.tqdm(pos_image_paths, desc=\"Pozytywne\"):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        img_resized = cv2.resize(img, target_size)\n",
    "        features = compute_hog(img_resized, **hog_params)\n",
    "        if features.size > 0:\n",
    "            hog_features_list.append(features)\n",
    "            labels_list.append(1)\n",
    "            \n",
    "    print(f\"Przetwarzanie {len(neg_image_paths)} obrazów negatywnych...\")\n",
    "    for img_path in tqdm.tqdm(neg_image_paths, desc=\"Negatywne\"):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        img_resized = cv2.resize(img, target_size)\n",
    "        features = compute_hog(img_resized, **hog_params)\n",
    "        if features.size > 0:\n",
    "            hog_features_list.append(features)\n",
    "            labels_list.append(0)\n",
    "            \n",
    "    return np.array(hog_features_list, dtype=np.float32), np.array(labels_list, dtype=np.int32)\n",
    "\n",
    "print(\"Funkcje 'load_image_paths' i 'prepare_training_data' zdefiniowane.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48279c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_SAMPLES_FOLDER = \"pedestrians/pos/\"\n",
    "NEGATIVE_SAMPLES_FOLDER = \"pedestrians/neg/\"\n",
    "NUM_SAMPLES_EACH_CLASS = 1000\n",
    "\n",
    "for folder in [POSITIVE_SAMPLES_FOLDER, NEGATIVE_SAMPLES_FOLDER]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "        print(f\"Utworzono folder {folder}. Proszę dodać obrazy.\")\n",
    "    if not os.listdir(folder) and NUM_SAMPLES_EACH_CLASS > 0:\n",
    "        print(f\"Ostrzeżenie: Folder {folder} jest pusty. Trening SVM może się nie udać.\")\n",
    "\n",
    "\n",
    "hog_parameters_train = {\n",
    "    'cell_size': (8, 8), 'num_bins': 9,\n",
    "    'block_size_cells': (2, 2), 'block_stride_cells': (1, 1),\n",
    "    'norm_epsilon': 1e-5\n",
    "}\n",
    "\n",
    "train_hog_features, train_labels = prepare_training_data(\n",
    "    POSITIVE_SAMPLES_FOLDER, NEGATIVE_SAMPLES_FOLDER,\n",
    "    NUM_SAMPLES_EACH_CLASS, hog_parameters_train\n",
    ")\n",
    "\n",
    "svm_classifier = None\n",
    "if train_hog_features.size > 0 and train_labels.size > 0:\n",
    "    print(f\"\\nPrzygotowano dane: {train_hog_features.shape[0]} próbek.\")\n",
    "    if train_hog_features.shape[0] > 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            train_hog_features, train_labels, test_size=0.1, random_state=42, stratify=train_labels\n",
    "        )\n",
    "        print(f\"Rozmiar zbioru treningowego: {X_train.shape[0]}, testowego: {X_test.shape[0]}\")\n",
    "\n",
    "        print(\"\\nTrening klasyfikatora SVM...\")\n",
    "        svm_classifier = svm.SVC(kernel='linear', C=1.0, probability=True)\n",
    "        svm_classifier.fit(X_train, y_train)\n",
    "        print(\"Trening zakończony.\")\n",
    "\n",
    "        print(\"\\nOcena klasyfikatora na zbiorze testowym (z podziału)...\")\n",
    "        predicted_labels_test = svm_classifier.predict(X_test)\n",
    "        cm_test = confusion_matrix(y_test, predicted_labels_test)\n",
    "        acc_test = accuracy_score(y_test, predicted_labels_test)\n",
    "        print(\"Macierz pomyłek (zbiór testowy):\")\n",
    "        print(cm_test)\n",
    "        print(f\"Dokładność na zbiorze testowym: {acc_test * 100:.2f}%\")\n",
    "    else:\n",
    "        print(\"Za mało danych do podziału na zbiór treningowy/testowy i treningu SVM.\")\n",
    "else:\n",
    "    print(\"Nie udało się przygotować wystarczających danych treningowych dla SVM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aec622",
   "metadata": {},
   "source": [
    "11.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df0376",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = (64, 128)\n",
    "HOG_PARAMS_DETECTION = hog_parameters_train\n",
    "\n",
    "def sliding_window_detection_matrix_input(image_matrix, window_size, step_size, svm_model, hog_params_dict):\n",
    "    detections = []\n",
    "    img_h, img_w = image_matrix.shape[:2]\n",
    "    win_w, win_h = window_size\n",
    "    \n",
    "    for y in tqdm.tqdm(range(0, img_h - win_h + 1, step_size), desc=\"Przesuwanie okna\", leave=False):\n",
    "        for x in range(0, img_w - win_w + 1, step_size):\n",
    "            window = image_matrix[y:y + win_h, x:x + win_w]\n",
    "            if window.shape[0] != win_h or window.shape[1] != win_w: continue\n",
    "            \n",
    "            hog_features_window = compute_hog(window, **hog_params_dict)\n",
    "            if hog_features_window.size == 0: continue\n",
    "\n",
    "            reshaped_hog = hog_features_window.reshape(1, -1)\n",
    "            confidence = svm_model.decision_function(reshaped_hog)[0]\n",
    "            \n",
    "            prediction = svm_model.predict(reshaped_hog)[0]\n",
    "\n",
    "            if prediction == 1: \n",
    "                detections.append((x, y, win_w, win_h, confidence))\n",
    "    return detections\n",
    "\n",
    "def non_max_suppression_cv(original_detections_list, overlap_thresh):\n",
    "    \n",
    "    if not original_detections_list: \n",
    "        return []\n",
    "\n",
    "    boxes_xywh = [[int(d[0]), int(d[1]), int(d[2]), int(d[3])] for d in original_detections_list]\n",
    "    scores = [float(d[4]) for d in original_detections_list]\n",
    "\n",
    "    score_thresh_for_nms = 0.0\n",
    "    \n",
    "    indices = cv2.dnn.NMSBoxes(boxes_xywh, scores, \n",
    "                               score_threshold=score_thresh_for_nms,\n",
    "                               nms_threshold=overlap_thresh)\n",
    "    \n",
    "    final_detections = []\n",
    "    if isinstance(indices, np.ndarray) and indices.size > 0:\n",
    "        for i in indices.flatten():\n",
    "            final_detections.append(original_detections_list[i])\n",
    "    elif isinstance(indices, tuple) and len(indices) > 0 and len(indices[0]) > 0:\n",
    "         for i in indices[0]:\n",
    "            final_detections.append(original_detections_list[i])\n",
    "            \n",
    "    return final_detections\n",
    "\n",
    "\n",
    "def detect_objects_and_show(image_path, svm_clf,\n",
    "                            window_sz=(64,128), stride_val=16,\n",
    "                            hog_prms=HOG_PARAMS_DETECTION,\n",
    "                            nms_thresh=0.1,\n",
    "                            n_scales=5,\n",
    "                            pyramid_scale_factor=1.2\n",
    "                           ):\n",
    "    if svm_clf is None:\n",
    "        print(\"Klasyfikator SVM nie jest wytrenowany. Pomijanie detekcji.\")\n",
    "        return\n",
    "\n",
    "    img_orig_bgr = cv2.imread(image_path)\n",
    "    if img_orig_bgr is None:\n",
    "        print(f\"Nie można wczytać obrazu testowego: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    img_orig_rgb = cv2.cvtColor(img_orig_bgr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    all_detections_multiscale = []\n",
    "\n",
    "    initial_h, initial_w = img_orig_rgb.shape[:2]\n",
    "    min_dim_after_scale = min(window_sz)\n",
    "    \n",
    "    current_scale_factor_total = 1.0\n",
    "    current_img_for_pyramid = img_orig_rgb.copy()\n",
    "\n",
    "    for scale_idx in tqdm.tqdm(range(n_scales), desc=f\"Skale dla {os.path.basename(image_path)}\", leave=False):\n",
    "        if scale_idx > 0:\n",
    "            new_w = int(current_img_for_pyramid.shape[1] / pyramid_scale_factor)\n",
    "            new_h = int(current_img_for_pyramid.shape[0] / pyramid_scale_factor)\n",
    "            if new_w < window_sz[0] or new_h < window_sz[1]:\n",
    "                break\n",
    "            current_img_for_pyramid = cv2.resize(current_img_for_pyramid, (new_w, new_h))\n",
    "            current_scale_factor_total *= pyramid_scale_factor\n",
    "        \n",
    "        detections_at_this_scale = sliding_window_detection_matrix_input(\n",
    "            current_img_for_pyramid, window_sz, stride_val, svm_clf, hog_prms\n",
    "        )\n",
    "        \n",
    "        for (x, y, w, h, conf) in detections_at_this_scale:\n",
    "            orig_x = int(x * current_scale_factor_total)\n",
    "            orig_y = int(y * current_scale_factor_total)\n",
    "            orig_w = int(w * current_scale_factor_total)\n",
    "            orig_h = int(h * current_scale_factor_total)\n",
    "            all_detections_multiscale.append((orig_x, orig_y, orig_w, orig_h, conf))\n",
    "\n",
    "    print(f\"Liczba detekcji przed NMS dla {os.path.basename(image_path)}: {len(all_detections_multiscale)}\")\n",
    "    \n",
    "    final_detections = non_max_suppression_cv(all_detections_multiscale, nms_thresh)\n",
    "\n",
    "    print(f\"Liczba detekcji po NMS dla {os.path.basename(image_path)}: {len(final_detections)}\")\n",
    "    \n",
    "    img_to_show_detections = img_orig_rgb.copy()\n",
    "    for (x, y, w, h, _) in final_detections:\n",
    "        cv2.rectangle(img_to_show_detections, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_to_show_detections)\n",
    "    plt.title(f\"Detekcje dla {os.path.basename(image_path)}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_image_dir = \"Test images-pedestrians/\"\n",
    "test_images_pdf = [\n",
    "    os.path.join(test_image_dir, \"testImage1.png\"),\n",
    "    os.path.join(test_image_dir, \"testImage2.png\"),\n",
    "    os.path.join(test_image_dir, \"testImage3.png\"),\n",
    "    os.path.join(test_image_dir, \"testImage4.png\")\n",
    "]\n",
    "\n",
    "if not os.path.exists(test_image_dir):\n",
    "    os.makedirs(test_image_dir)\n",
    "    print(f\"Utworzono folder {test_image_dir}. Proszę dodać obrazy testowe.\")\n",
    "\n",
    "for img_path_test in test_images_pdf:\n",
    "    if not os.path.exists(img_path_test):\n",
    "        print(f\"Plik testowy {img_path_test} nie istnieje. Tworzę dummy obraz.\")\n",
    "        dummy_test = np.zeros((300, 400, 3), dtype=np.uint8) \n",
    "        cv2.rectangle(dummy_test, (100,50), (100+64, 50+128), (200,100,50), -1)\n",
    "        cv2.imwrite(img_path_test, dummy_test)\n",
    "    \n",
    "    print(f\"\\n--- Detekcja dla: {os.path.basename(img_path_test)} ---\")\n",
    "    detect_objects_and_show(img_path_test, svm_classifier, stride_val=16, n_scales=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
